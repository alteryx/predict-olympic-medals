{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Featuretools to analyze medals won at the Olympic Games\n",
    "\n",
    "In this notebook, we will examine a dataset containing all the medals won by each athlete at each Summer Olympic Games. Our goal will be to see what quantities are important in predicting the future number of medals won.\n",
    "\n",
    "To do this, we will build a machine-learning-based predictive model that is trained on historical data, and used to predict the number of medals won by each country in the next Olympics. We'll build this model using high-level transformations of the data &mdash; called features &mdash; that are automatically generated from Featuretools. [Featuretools](https://featuretools.com) is a Python library for [automated feature engineering]().\n",
    "\n",
    "This notebook will serve as an introduction to Featuretools, but does not explain each function call in depth. See the [documentation](https://docs.featuretools.com) for a more thorough usage guide.\n",
    "\n",
    "## Disclaimer on suitability of the dataset and problem\n",
    "\n",
    "Ordinary machine learning with bare-bones features allows us\n",
    "to predict the\n",
    "quantities we care about in this example extremely\n",
    "well. That means that advanced high-level features\n",
    "from Featuretools do not produce much improvement.\n",
    "However, they provide much more interpretable\n",
    "predictive factors, which lets us examine which\n",
    "ones were important and which ones we care about. In the other notebooks\n",
    "in this repo, we will see how to use the more\n",
    "advanced components of Featuretools to increase our\n",
    "scores. Perhaps more importantly, we will also see how new feature types compare to each other in predictive poower in a relative way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import featuretools as ft\n",
    "from featuretools import primitives as prims\n",
    "from featuretools.selection.variance_selection import (\n",
    "    select_high_variance_features,\n",
    "    select_percent_null)\n",
    "import os\n",
    "from ml import (bin_labels,\n",
    "                TimeSeriesSplitByDate,\n",
    "                fit_and_score)\n",
    "from load_entityset import load_entityset\n",
    "from utils import (build_baseline_features,\n",
    "                   get_feature_importances,\n",
    "                   plot_confusion_matrix,\n",
    "                   select_non_null_features,\n",
    "                   select_multivalued_features)\n",
    "from IPython.display import display\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA_FOLDER = os.path.expanduser(\"~/olympic_games_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load in data\n",
    "\n",
    "`EntitySet` is the in-memory data structure Featuretools uses to build and calculate features. It essentially consists of:\n",
    " * a dictionary of [Pandas DataFrames](https://pandas.pydata.org/pandas-docs/stable/dsintro.html)\n",
    " * associated metadata on how they are linked\n",
    " * what semantic types they contain\n",
    " * how they vary in time.\n",
    " \n",
    "For more details and tutorials, check out the [documentation](https://docs.featuretools.com/loading_data/using_entitysets.html).\n",
    "\n",
    "To examine the following function in more detail, check out [load_entityset.py](load_entityset.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: Olympic Games\n",
       "  Entities:\n",
       "    disciplines (shape = [67, 3])\n",
       "    countries (shape = [220, 8])\n",
       "    olympic_games (shape = [27, 3])\n",
       "    medals_won (shape = [11532, 7])\n",
       "    sports (shape = [43, 2])\n",
       "    ...And 3 more\n",
       "  Relationships:\n",
       "    medaling_athletes.Athlete -> athletes.Athlete\n",
       "    medals_won.Country Olympic ID -> countries_at_olympic_games.Country Olympic ID\n",
       "    countries_at_olympic_games.Olympic Games ID -> olympic_games.Olympic Games ID\n",
       "    medals_won.Discipline -> disciplines.Discipline\n",
       "    disciplines.Sport -> sports.Sport\n",
       "    ...and 2 more"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = load_entityset(with_next_competing_info=True)\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Olympic ID</th>\n",
       "      <th>Olympic Games Name</th>\n",
       "      <th>Olympic Games ID</th>\n",
       "      <th>Country</th>\n",
       "      <th>CompetedNextOlympics</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country Olympic ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Athens 1896-06-30</td>\n",
       "      <td>0</td>\n",
       "      <td>HUN</td>\n",
       "      <td>True</td>\n",
       "      <td>1896-06-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Athens 1896-06-30</td>\n",
       "      <td>0</td>\n",
       "      <td>GRE</td>\n",
       "      <td>True</td>\n",
       "      <td>1896-06-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Athens 1896-06-30</td>\n",
       "      <td>0</td>\n",
       "      <td>GER</td>\n",
       "      <td>True</td>\n",
       "      <td>1896-06-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Athens 1896-06-30</td>\n",
       "      <td>0</td>\n",
       "      <td>ZZX</td>\n",
       "      <td>True</td>\n",
       "      <td>1896-06-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Athens 1896-06-30</td>\n",
       "      <td>0</td>\n",
       "      <td>GBR</td>\n",
       "      <td>True</td>\n",
       "      <td>1896-06-30 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Country Olympic ID Olympic Games Name  Olympic Games ID  \\\n",
       "Country Olympic ID                                                            \n",
       "0                                    0  Athens 1896-06-30                 0   \n",
       "1                                    1  Athens 1896-06-30                 0   \n",
       "2                                    2  Athens 1896-06-30                 0   \n",
       "3                                    3  Athens 1896-06-30                 0   \n",
       "4                                    4  Athens 1896-06-30                 0   \n",
       "\n",
       "                   Country  CompetedNextOlympics                Year  \n",
       "Country Olympic ID                                                    \n",
       "0                      HUN                  True 1896-06-30 00:00:00  \n",
       "1                      GRE                  True 1896-06-30 00:00:00  \n",
       "2                      GER                  True 1896-06-30 00:00:00  \n",
       "3                      ZZX                  True 1896-06-30 00:00:00  \n",
       "4                      GBR                  True 1896-06-30 00:00:00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es['countries_at_olympic_games'].df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labels and cutoff times\n",
    "\n",
    "Machine learning (in its [supervised](http://scikit-learn.org/stable/supervised_learning.html) flavor) is all about predicting a set of labels, given a set of training data. This is canonically represented by a *feature matrix*, whose rows are each numeric vectors of fixed length. Each row is associated with a single value, called a label. The machine learning algorithm is tasked with building a model that is good at predicting the label given the row vector.\n",
    "\n",
    "In *predictive modeling*, the labels represent future\n",
    "quantities. This makes the time associated with the\n",
    "label crucial, since it might mean we can't use some\n",
    "of the data. If we're trying to train our model to a\n",
    "predict a label that happened last Tuesday, we shouldn't be\n",
    "using the numbers from today.\n",
    "\n",
    "In this particular case, our goal is to predict the number of medals won by each country in each subsequent Olympic Games, so our labels will be uniquely defined by a particular country and date of particular Olympic Games in which it competed.\n",
    "\n",
    "[Coming Soon] Check out [GeneratingLabels.ipynb](GeneratingLabels.ipynb) for a walkthrough of how I generated these labels.\n",
    "\n",
    "[Feature Labs](https://www.featurelabs.com/), the company that I work for and that maintains Featuretools, sells a platform that, among other things, makes this label generation process extremely easy. This process is known as [Prediction Engineering](https://www.featurelabs.com/resources/why.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Medals</th>\n",
       "      <th>Olympics Date</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1896-06-29 00:00:00</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>1896-06-29 00:00:00</td>\n",
       "      <td>AUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1896-06-29 00:00:00</td>\n",
       "      <td>DEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1896-06-29 00:00:00</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1896-06-29 00:00:00</td>\n",
       "      <td>GBR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of Medals       Olympics Date Country\n",
       "8                  2 1896-06-29 00:00:00     AUS\n",
       "9                  5 1896-06-29 00:00:00     AUT\n",
       "5                  6 1896-06-29 00:00:00     DEN\n",
       "10                11 1896-06-29 00:00:00     FRA\n",
       "4                  7 1896-06-29 00:00:00     GBR"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_file = os.path.join(ROOT_DATA_FOLDER, \"num_medals_by_country_labels.csv\")\n",
    "label_df = pd.read_csv(label_file,\n",
    "                       parse_dates=['Olympics Date'],\n",
    "                       encoding='utf-8',\n",
    "                       usecols=['Number of Medals', 'Olympics Date', 'Country'])\n",
    "# Sort by the date of the Olympics, and by the country (to maintain a consistent ordering)\n",
    "label_df.sort_values(['Olympics Date', 'Country'], inplace=True)\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features Using Deep Feature Synthesis\n",
    "\n",
    "\n",
    "Featuretools automatically extracts high-level, interpretable features from EntitySets. This means we can exhaustively create many features, and use these to train our machine learning predictive model.\n",
    "\n",
    "Moreover, it makes sure to calculate these features only using data on or before specified *cutoff times*. This is a subtle but immensely important point &mdash; I'll refer you to the [documentation](https://docs.featuretools.com/automated_feature_engineering/handling_time.html) for deeper understanding. In this case, these cutoff times will be dates immediately prior to each Olympic Games. They are specified in the label file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just want the Country and time to compute features (we're removing the label column here)\n",
    "cutoff_times = label_df[['Country', 'Olympics Date']]\n",
    "# Code is the index of the \"countries\" entity in the entityset (short for Country Code)\n",
    "cutoff_times = cutoff_times.rename(columns={'Country': 'Code'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the particular primitives we want Featuretools to use to construct features. Featuretools will walk through our EntitySet and apply these primitives recursively using the [Deep Feature Synthesis](https://docs.featuretools.com/automated_feature_engineering/afe.html) algorithm. These primitives are basic functions that take a particular data type as input (such as a Numeric or Categorical), and output a single value per *instance* (row) of an entity.\n",
    "\n",
    "Transform primitives take each instance of an entity and apply a function to each row.\n",
    "\n",
    "Aggregation primitives take 2 entities, where each row in the *parent* entity is connected to many rows in the *child*, and apply a function to all the rows in the *child* connected to a single *parent* row.\n",
    "\n",
    "\n",
    "These primitives are defined in more detail [here](https://docs.featuretools.com/automated_feature_engineering/primitives.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_primitives = [\n",
    "    prims.Sum, prims.Std, prims.Max, prims.Min, prims.Mean, prims.Count,\n",
    "    prims.PercentTrue, prims.NUnique, prims.Mode, prims.Trend, prims.Skew\n",
    "]\n",
    "trans_primitives = [\n",
    "    prims.Percentile\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison to a Baseline\n",
    "\n",
    "We want to make sure we use the features we used for our simple baseline model for a fair comparison to our more interpretable Featuretools model. To do this, we define these features manually using Featuretools, and add them in as *seed features* to DFS. This will not only include these features directly, but will also build higher-level features on top of them.\n",
    "\n",
    "For a more thorough walkthrough of the baseline, check out [BaselineSolutions.ipynb](BaselineSolutions.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include our baseline predictors as seed features\n",
    "num_medals_each_olympics, mean_num_medals = build_baseline_features(es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DFS\n",
    "\n",
    "A note on the parameter settings:\n",
    "  * `target_entity` defines the entity containing unique rows (called *instances*) for each training example. \n",
    "  * `trans_primitives` is a list of *transform* primitive classes.\n",
    "  * `agg_primitives` is a list of *aggregation* primitive classes.\n",
    "  * `max_depth` defines how *deep* we build features on top of one another ([explanation](https://docs.featuretools.com/automated_feature_engineering/afe.html#creating-deep-features))\n",
    "  * `cutoff_times` is a Pandas DataFrame with a column for defining each instance we want to compute features for, and its associated cutoff time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features: 2847it [00:03, 671.65it/s] \n",
      "Progress:   4%|â–Ž         | 1/27 [00:02<01:11,  2.75s/cutoff time]"
     ]
    }
   ],
   "source": [
    "feature_matrix, features = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_entity=\"countries\",\n",
    "    trans_primitives=trans_primitives,\n",
    "    agg_primitives=agg_primitives,\n",
    "    max_depth=4,\n",
    "    seed_features=num_medals_each_olympics + [mean_num_medals],\n",
    "    cutoff_time=cutoff_times,\n",
    "    verbose=True)\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove features with zero variance or almost all null\n",
    "\n",
    "Featuretools contains a couple handy functions for removing features with all null values or zero variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, features = select_non_null_features(feature_matrix, features)\n",
    "\n",
    "print \"%d features selected\" % len(features)\n",
    "\n",
    "feature_matrix, features = select_multivalued_features(feature_matrix, features)\n",
    "\n",
    "print \"%d features selected\" % len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot-encode categorical features\n",
    "\n",
    "Machine learning algorithms require all numeric values as input, but Featuretools by default produces some categorical values. One way to transform these values into numbers is to create several binary features that encode whether the feature is equal to each particular category (by default capped at the top 10 most common categories). To learn more check out this [docs page](https://docs.featuretools.com/guides/tuning_dfs.html#encoding-categorical-features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_encoded, features_encoded = ft.encode_features(feature_matrix, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarize and bin labels\n",
    "\n",
    "We'll actually create 3 slightly different models:\n",
    "\n",
    "  1. **Regression** Predicting the actual number of medals per country\n",
    "  2. **Binary Classification** Predicting whether the number of medals is greater than 10.\n",
    "  3. **Binned Classification** Predicting which bin the medals falls into (i.e. between 0 and 2, 2 and 6, 6 and 10, 10 and 50, or greater than 50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = label_df['Olympics Date']\n",
    "labels = label_df['Number of Medals']\n",
    "binned_labels, bins = bin_labels(labels, [2, 6, 10, 50])\n",
    "binary_labels = (labels >= 10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate out the baseline features\n",
    "\n",
    "These are for the slightly more complex, machine-learning-based \"Baseline 2\" from [BaselineSolutions.ipynb](BaselineSolutions.ipynb). Since the other baseline is not machine-learning-based, refer to that notebook for scores and analysis (they are significantly worse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_baseline = feature_matrix_encoded[[\n",
    "    f.get_name() for f in num_medals_each_olympics\n",
    "    if f.get_name() in feature_matrix_encoded\n",
    "]]\n",
    "just_baseline.iloc[-10:, -10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build machine learning models and generate scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create scikit-learn estimators\n",
    "\n",
    "We'll use stock machine learning algorithms from scikit-learn, as well as an imputer that replaces missing values with the mean over that feature, and a scaler that makes sure each feature's values vary from 0 to 1. The `RobustScaler` class is more sensitive to outliers than the `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_preprocessing = [(\"imputer\",\n",
    "                           Imputer(missing_values='NaN', strategy=\"mean\", axis=0)),\n",
    "                          (\"scaler\", RobustScaler(with_centering=True))]\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-based cross-validation\n",
    "\n",
    "The way we'll do cross-validation is to separate training sets for each Olympics since 1960, using all historical data in the past for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = TimeSeriesSplitByDate(dates=dates, earliest_date=pd.Timestamp('1/1/1960'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_matrix_encoded.values\n",
    "y = labels.values\n",
    "y_binary = binary_labels.values\n",
    "y_binned = binned_labels.values\n",
    "X_baseline = just_baseline.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "`fit_and_score` takes in a feature matrix, labels, splitter, and the machine learning pipeline, builds models for each split, and scores each one using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pipeline = Pipeline(pipeline_preprocessing + [(\"rf_reg\", rf_reg)])\n",
    "scores = fit_and_score(X, y, splitter, reg_pipeline, _type='regression')\n",
    "baseline_scores = fit_and_score(X_baseline, y, splitter, reg_pipeline, _type='regression')\n",
    "print \"Regression model\"\n",
    "print \"  R2 mean score:  %.2f +/- %.2f\" % (scores['r2'].mean(),\n",
    "                                           scores['r2'].std())\n",
    "print \"  Baseline R2 mean score:  %.2f +/- %.2f\" % (baseline_scores['r2'].mean(),\n",
    "                                                    baseline_scores['r2'].std())\n",
    "print \"  MSE mean score:  %.2f +/- %.2f\" % (scores['mse'].mean(),\n",
    "                                            scores['mse'].std())\n",
    "print \"  Baseline MSE mean score:  %.2f +/- %.2f\" % (baseline_scores['mse'].mean(),\n",
    "                                                         baseline_scores['mse'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(pipeline_preprocessing + [('rf_clf', rf_clf)])\n",
    "binary_scores = fit_and_score(X, y_binary, splitter, pipeline, _type='classification')\n",
    "baseline_binary_scores = fit_and_score(X_baseline, y_binary, splitter, pipeline, _type='classification')\n",
    "binned_scores = fit_and_score(X, y_binned, splitter, pipeline, _type='classification')\n",
    "baseline_binned_scores = fit_and_score(X_baseline, y_binned, splitter, pipeline, _type='classification')\n",
    "print \"Classification model\"\n",
    "print \"  AUC mean score:  %.2f +/- %.2f\" % (binary_scores['roc_auc'].mean(),\n",
    "                                            binary_scores['roc_auc'].std())\n",
    "print \"  Baseline AUC mean score:  %.2f +/- %.2f\" % (baseline_binary_scores['roc_auc'].mean(),\n",
    "                                                     baseline_binary_scores['roc_auc'].std())\n",
    "print \"  F1 mean score:  %.2f +/- %.2f\" % (binary_scores['f1'].mean(),\n",
    "                                           binary_scores['f1'].std())\n",
    "print \"  Baseline F1 mean score:  %.2f +/- %.2f\" % (baseline_binary_scores['f1'].mean(),\n",
    "                                                    baseline_binary_scores['f1'].std())\n",
    "print \"  Binned F1 (micro averaged) mean score:  %.2f +/- %.2f\" % (binned_scores['f1_micro'].mean(),\n",
    "                                                                   binned_scores['f1_micro'].std())\n",
    "print \"  Baseline Binned F1 (micro averaged) mean score:  %.2f +/- %.2f\" % (baseline_binned_scores['f1_micro'].mean(),\n",
    "                                                                            baseline_binned_scores['f1_micro'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing scores across years\n",
    "\n",
    "We'll plot the scores over time for each type of problem, and then look at a few confusion matrices for particular years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the regression scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.set_index('Olympics Year')['r2'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the binned scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_scores.set_index('Olympics Year')['f1_micro'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the binary scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_scores.set_index('Olympics Year')['f1'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the binned problem is harder in different years than the regression problem. 1984 is a terrible year for the binned predictor, while 1992 is much worse for the regression predictor. The binary score is on the whole smoother over time, but still has a major hiccup in 1984."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices\n",
    "\n",
    "The confusion matrix is a good way to quickly see well a model is predicting binary outcomes. For an intro to what these are, see Scikit-Learn's [User Guide](http://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix).\n",
    "Let's plot the confusion matrix for 1984 (a hard-to-predict year) and 2004 (an easy-to-predict year) (using code taken from Scikit-Learn [here](http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1984 = 5th split\n",
    "split, year = 5, '1984'\n",
    "train, test = splitter.split(X, y_binary)[split]\n",
    "pipeline.fit(X[train], y_binary[train])\n",
    "y_pred = pipeline.predict(X[test])\n",
    "cm = confusion_matrix(y_binary[test], y_pred)\n",
    "plot_confusion_matrix(cm, ['Won < 10 Medals', 'Won >= 10 Medals'], title=year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2004 = 10th split\n",
    "split, year = 10, '2004'\n",
    "train, test = splitter.split(X, y_binary)[split]\n",
    "pipeline.fit(X[train], y_binary[train])\n",
    "y_pred = pipeline.predict(X[test])\n",
    "cm = confusion_matrix(y_binary[test], y_pred)\n",
    "plot_confusion_matrix(cm, ['Won < 10 Medals', 'Won >= 10 Medals'], title=year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 1984, we underestimated how many medals 8 countries scored, while in 2004, we underestimated only 2 countres and overestimated 2. As we'll see later, this is probably due to the boycott in 1984 by Soviet Bloc countries, leading to higher medals scored by the democratic nations like the USA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to baseline\n",
    "\n",
    "As mentioned in the disclaimer at the top, we actually do almost exactly the same as our baseline. The reason for this is most likely two-fold:\n",
    "1. This is in general a very easy problem.\n",
    "2. For particular cases this is a very hard problem for which additional data is needed to make better predictions.\n",
    "\n",
    "We will examine the second issue in a future notebook. The problem arises from the fact that many outside factors contribute to weird outcomes at the Olympics which don't exist in our dataset. Boycotts and steroid scandals are a key example. Using only this current dataset detailing each medal that was won, there is no way for us to know which countries refrained from competing or which were disqualified after the fact.\n",
    "\n",
    "However, our interpretable features now provide us with a way to examine which hidden factors are predictive of the outcome. The baseline features are essentially uninterpretable- they are simply the number of medals scored at each prior Olympic Games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine feature importances\n",
    "\n",
    "This utility function grabs the Scikit-Learn Random Forest's built in feature importances, sorts them, and groups them by time split. These refer to how much weight the algorithm placed on each feature in order to predict the labels. \n",
    "\n",
    "We'll print out the top 10 highest weighted features for each Olympics since 1960."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imps_over_time = get_feature_importances(pipeline,\n",
    "                                                 feature_matrix_encoded,\n",
    "                                                 binary_labels,\n",
    "                                                 splitter,\n",
    "                                                 n=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_year in [1964, 2012]:\n",
    "    print \"Test year: %s\" % test_year\n",
    "    test_date = pd.Timestamp('6/29/{}'.format(test_year))\n",
    "    display(feature_imps_over_time[test_date].iloc[:10].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that features built on Baseline 1 (\"mean_num_medals\") are pretty high up in the list, but we do some interesting transformations on them. In particular, the Percentile feature is represented across the board.\n",
    "\n",
    "We will examine particular features and what they mean in more depth later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Feature Selection\n",
    "\n",
    "One interesting workflow that Featuretools allows is the ability to select a subset of features from an exhaustive list based on which ones the RandomForest placed a lot of weight on.\n",
    "\n",
    "To do this, let's rerun the computation using just the top 400 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top400 = feature_imps_over_time[pd.Timestamp('6/29/2012')]['Feature'].tolist()\n",
    "important_feature_matrix = feature_matrix_encoded[top400]\n",
    "\n",
    "pipeline = Pipeline(pipeline_preprocessing + [('rf_clf', rf_clf)])\n",
    "binned_scores = fit_and_score(important_feature_matrix.values, y_binned, splitter, pipeline, _type='classification')\n",
    "print \"  F1 micro mean score:  %.2f +/- %.2f\" % (binned_scores['f1_micro'].mean(),\n",
    "                                                 binned_scores['f1_micro'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison to full feature set\n",
    "\n",
    "We do approximately the same as our original model. What's more interesting is that we now have a smaller set of highly explainable features. We can reduce this feature set even more without a drop in accuracy. Here it is with 50 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feature_matrix = feature_matrix[top400[:50]]\n",
    "pipeline = Pipeline(pipeline_preprocessing + [('rf_clf', rf_clf)])\n",
    "binned_scores = fit_and_score(important_feature_matrix.values, y_binned, splitter, pipeline, _type='classification')\n",
    "print \"  F1 micro mean score:  %.2f +/- %.2f\" % (binned_scores['f1_micro'].mean(),\n",
    "                                                 binned_scores['f1_micro'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smaller set of important features\n",
    "\n",
    "Now let's take a closer look at the highest weighted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imps_over_time = get_feature_importances(pipeline,\n",
    "                                                 important_feature_matrix,\n",
    "                                                 binary_labels,\n",
    "                                                 splitter,\n",
    "                                                 n=50)\n",
    "\n",
    "for test_year in [1964, 1976, 2012]:\n",
    "    print \"Test year: %s\" % test_year\n",
    "    test_date = pd.Timestamp('6/29/{}'.format(test_year))\n",
    "    display(feature_imps_over_time[test_date].iloc[:10].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see some interesting thins.\n",
    "\n",
    "For one, the important features make a lot of sense. For 1964, the most important feature is `PERCENTILE(COUNT(medals_won WHERE Medal = Gold))`. This refers to the percentile across all countries of the count of gold medals won in all previous Olympics.\n",
    "\n",
    "The top feature in 1976 is more complicated but makes sense once we parse it. It's `MEAN(countries_at_olympic_games.PERCENTILE(NUM_UNIQUE(medals_won.MODE(medaling_athletes.Athlete))))`. This is a convoluted way of saying take the number of unique medaling athletes at each olympics a country competed in, find the percentile of that number in relation to the other countries, and take the average percentile over time. In other words, the average rank of the number of medaling athletes over time. The Mode part is an overcomplication that does not provide any additional information. So, if this value was high, it means that the country had on average a lot of medaling athletes in its historical Olympic showings.\n",
    "\n",
    "In 2012, a few features down we have `TREND(countries_at_olympic_games.SKEW(medals_won.NUM_UNIQUE(medaling_athletes.Athlete)), Year)`. The way we have out data set up, each medal can be associated with many athletes (think: all the members of the medaling Soccer team). Therefore, this feature is looking at the skew (a statistical measure indicating whether more of the values lie toward the left or the right of the mean) of how many athletes there were per medal, and finding the the slope of a trend line fitted these skew numbers over time. One way to think of the skew number is whether the country won more medals in team sports than in individual sports, and the trend shows how that changes over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why were some years difficult to predict?\n",
    "Specifically, the years between 1970 and 1992 showed high variability in scores.\n",
    "\n",
    "The Olympics in the 1980s were marred by controversies. Summarizing the\n",
    "[Wikipedia article](https://en.wikipedia.org/wiki/List_of_Olympic_Games_scandals_and_controversies):\n",
    "1. Rule changes\n",
    "   - This is the period that the IOC gradually started allowing professional\n",
    "   athletes\n",
    "2. Geopolitics\n",
    "   - Widespread boycotts due to the Cold War\n",
    "   - Montreal 1976: 22 African nations boycotted (to protest New Zealand's\n",
    "   rugby team's tour of South Africa during Apartheid). China and Taiwan both\n",
    "   boycotted. Fewest number of countries (92) participating since 1960.\n",
    "   - Moscow 1980: US boycotts because of Soviet invasion of Afghanistan.\n",
    "      Even fewer number of countries (80) than 1976\n",
    "   - Los Angeles 1984: Soviet Union and 15 Eastern Bloc nations boycott\n",
    "   because of \"safety concerns\". (However, a record 140 National Olympic\n",
    "   Committees took part)\n",
    "      Even fewer number of countries (80) than 1976\n",
    "3. Performance-enhancing Drugs\n",
    "   - late 1970s and especially 1980s ushered in the era of steroids\n",
    "   - quote from 1989 Australian study \"There is hardly a medal winner at the\n",
    "   Moscow Games, certainly not a gold medal winner, who is not on one sort of\n",
    "   drug or another: usually several kinds. The Moscow Games might as well have\n",
    "   been called the Chemists' Games.\" See the wiki\n",
    "   [page](https://en.wikipedia.org/wiki/Olympic_Games#Use_of_performance-enhancing_drugs), citation 183.\n",
    "4. Gender discrimination\n",
    "   - Many countries didn't send women until the late 1990s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Coming Soon] For a more in-depth analysis, check out [AdvancedFeaturetools.ipynb](AdvancedFeaturetools.ipynb) and [LinkingDatasets.ipynb](LinkingDatasets.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's make a prediction about the 2016 olympics\n",
    "\n",
    "We've trained models to predict the highest medaling countries in past Olympic Games, so we might as well use those models to predict who will receive the most medals in the next Olympics. This dataset came out before 2016, so we can compare to what actually happened. Unfortunately, the way our model is set up we would have to add in the 2016 data to make predictions about 2020 (I'll leave that up to you to try out yourself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on all data\n",
    "reg_pipeline.fit(important_feature_matrix, y)\n",
    "\n",
    "# Get the top feature objects to compute\n",
    "important_features = {f.get_name(): f for f in features_encoded\n",
    "                      if f.get_name() in important_feature_matrix.columns}.values()\n",
    "# Compute feature matrix on all data (no cutoff time)\n",
    "# Leave cutoff_date blank to use the current time\n",
    "df = es['countries_at_olympic_games'].df\n",
    "countries_2012 = df.loc[df['Year'] == pd.Timestamp('2012-06-30'), 'Country']\n",
    "latest_fm = ft.calculate_feature_matrix(features=important_features,\n",
    "                                        instance_ids=countries_2012,\n",
    "                                        cutoff_time=None,\n",
    "                                        verbose=True)\n",
    "# Make sure order is correct\n",
    "latest_fm = latest_fm[important_feature_matrix.columns]\n",
    "\n",
    "predictions = reg_pipeline.predict(latest_fm)\n",
    "predictions_by_country = pd.Series(predictions, index=latest_fm.index)\n",
    "predictions_by_country.sort_values(ascending=False, inplace=True)\n",
    "predictions_by_country.head(20).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual medal count is available [here](https://en.wikipedia.org/wiki/2016_Summer_Olympics_medal_table).\n",
    "I took the first 20 to plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_2016 = pd.DataFrame.from_records([('USA', 121),\n",
    "('CHN', 70) ,\n",
    "('GBR', 67) ,\n",
    "('RUS', 56) ,\n",
    "('GER', 42) ,\n",
    "('FRA', 42) ,\n",
    "('JPN', 41) ,\n",
    "('AUS', 29) ,\n",
    "('ITA', 28) ,\n",
    "('CAN', 22) ,\n",
    "('KOR', 21) ,\n",
    "('NED', 19) ,\n",
    "('BRA', 19) ,\n",
    "('NZL', 18) ,\n",
    "('KAZ', 18) ,\n",
    "('AZE', 18) ,\n",
    "('ESP', 17) ,\n",
    "('HUN', 15) ,\n",
    "('DEN', 15) ,\n",
    "('KEN', 1)], columns=['Country', 'Medals']).set_index(['Country'])['Medals']\n",
    "\n",
    "actual_2016.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we overestimated Russia and underestimated Great Britain and China!\n",
    "\n",
    "However- recall that in this past Olympics Russia was implicated in a major state-sponsored doping scandal. This resulted in the disqualification of essentially the entire track & field team. So Russia would otherwise probably have score many more medals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A fun prediction\n",
    "Our data includes all the countries that have ever medaled in any Olympics. There's nothing stopping us from generating predictions for defunct countries. Let's see what happens if we predict the number of medals won in 2016 for every historical country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave instance_ids blank to use all\n",
    "latest_fm = ft.calculate_feature_matrix(features=important_features,\n",
    "                                        cutoff_time=None,\n",
    "                                        verbose=True)\n",
    "# Make sure order is correct\n",
    "latest_fm = latest_fm[important_feature_matrix.columns]\n",
    "\n",
    "predictions = reg_pipeline.predict(latest_fm)\n",
    "predictions_by_country = pd.Series(predictions, index=latest_fm.index)\n",
    "predictions_by_country.sort_values(ascending=False, inplace=True)\n",
    "predictions_by_country.head(20).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model thinks that if the former Soviet Union were alive today it would win it all, the unified post-Soviet breakup team (EUN) would come in 3rd, and both East Germany (GDR) and West Germany (FRG) would come out ahead of modern-day Germany (GER)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
